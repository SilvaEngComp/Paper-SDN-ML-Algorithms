{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from timeit import default_timer as timer\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(X, y, time_steps=1):\n",
    "    Xs, ys = [], []    \n",
    "    for i in range(len(X) - time_steps):\n",
    "        clear_output(wait=True)\n",
    "        print('modeling to keras ',round((i/(len(X) - time_steps))*100,2), ('%'), end='')\n",
    "        s = round(timer() - start)\n",
    "        if(s>60):\n",
    "            s /=60\n",
    "            print(' ', s, ' seconds')\n",
    "        v = X.iloc[i: (i+time_steps), 2:4].to_numpy()\n",
    "        Xs.append(v)\n",
    "        ys.append(y.iloc[i+time_steps])\n",
    "    return np.array(Xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset...\n"
     ]
    }
   ],
   "source": [
    "#carregando datasets\n",
    "print('loading dataset...')\n",
    "train = pd.read_csv('../datasets/com_concept_drift/sdn_train_unormalized.csv')\n",
    "test = pd.read_csv('../datasets/com_concept_drift/sdn_test_unormalized.csv')\n",
    "\n",
    "train = train[train.delay>=0]\n",
    "test = test[test.delay>=0]\n",
    "\n",
    "train = train[train.delay<=10000] \n",
    "test = test[test.delay<=10000] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modeling to keras  99.81 %  11.133333333333333  seconds\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "print('creating window')\n",
    "TIME_STEPS = 1\n",
    "X_train,Y_train = create_dataset(train, train.delay, time_steps=TIME_STEPS)\n",
    "X_test,Y_test = create_dataset(test, test.delay, time_steps=TIME_STEPS)\n",
    "\n",
    "print('2D to 3D duration: ', round(timer() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setting MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configurando rede para treinamento\n",
    "print('Init Train')\n",
    "model = keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(activation=\"relu\", input_dim=2, units=10, kernel_initializer='uniform'))\n",
    "model.add(tf.keras.layers.Dense(activation=\"relu\", units=128, kernel_initializer='uniform'))\n",
    "model.add(tf.keras.layers.Dense(activation=\"relu\", units=128, kernel_initializer='uniform'))\n",
    "model.add(tf.keras.layers.Dense(activation=\"relu\", units=128, kernel_initializer='uniform'))\n",
    "model.add(keras.layers.Dropout(rate=0.2))\n",
    "model.add(keras.layers.Dense(units=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss =\"mse\"\n",
    "optim = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.0001)\n",
    "metrics=[\"accuracy\"]\n",
    "\n",
    "model.compile(loss=loss, optimizer=optim, \n",
    "             metrics=metrics\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Train\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 2) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 1, 2).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 2) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 1, 2).\n",
      "4979/4995 [============================>.] - ETA: 0s - loss: 12620.5869 - accuracy: 0.6480WARNING:tensorflow:Model was constructed with shape (None, 2) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 1, 2).\n",
      "4995/4995 [==============================] - 20s 3ms/step - loss: 14563.4932 - accuracy: 0.6461 - val_loss: 18984.5566 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "4995/4995 [==============================] - 16s 3ms/step - loss: 14593.8555 - accuracy: 0.0000e+00 - val_loss: 19057.5508 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "4995/4995 [==============================] - 14s 3ms/step - loss: 14554.5801 - accuracy: 0.0000e+00 - val_loss: 19092.3496 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "4995/4995 [==============================] - 13s 3ms/step - loss: 14517.0762 - accuracy: 0.0000e+00 - val_loss: 19077.9277 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "4995/4995 [==============================] - 12s 2ms/step - loss: 14431.0537 - accuracy: 0.1121 - val_loss: 19162.8281 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "4995/4995 [==============================] - 11s 2ms/step - loss: 14296.5068 - accuracy: 4.0047e-05 - val_loss: 19064.8398 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "4995/4995 [==============================] - 12s 2ms/step - loss: 13916.9912 - accuracy: 0.0605 - val_loss: 18715.9102 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "4995/4995 [==============================] - 12s 2ms/step - loss: 12380.6152 - accuracy: 0.1992 - val_loss: 16378.9629 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "4995/4995 [==============================] - 12s 2ms/step - loss: 6440.5112 - accuracy: 0.2893 - val_loss: 9201.4053 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "4995/4995 [==============================] - 12s 2ms/step - loss: 2070.7917 - accuracy: 0.6350 - val_loss: 7322.8120 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "4995/4995 [==============================] - 12s 2ms/step - loss: 1696.8521 - accuracy: 0.6364 - val_loss: 4738.6211 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "4995/4995 [==============================] - 12s 2ms/step - loss: 1796.2686 - accuracy: 0.6027 - val_loss: 1496.8722 - val_accuracy: 0.2948\n",
      "Epoch 13/100\n",
      "4995/4995 [==============================] - 13s 3ms/step - loss: 1913.7960 - accuracy: 0.5698 - val_loss: 1594.4114 - val_accuracy: 0.0627\n",
      "Epoch 14/100\n",
      "4995/4995 [==============================] - 13s 3ms/step - loss: 1955.7272 - accuracy: 0.5538 - val_loss: 1535.4669 - val_accuracy: 0.0515\n",
      "Epoch 15/100\n",
      "4995/4995 [==============================] - 12s 2ms/step - loss: 1921.5026 - accuracy: 0.5614 - val_loss: 1486.8374 - val_accuracy: 0.0315\n",
      "Epoch 16/100\n",
      "4995/4995 [==============================] - 13s 3ms/step - loss: 1909.7012 - accuracy: 0.5715 - val_loss: 1486.8312 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "4995/4995 [==============================] - 13s 3ms/step - loss: 1972.1023 - accuracy: 0.5714 - val_loss: 1496.3660 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "4995/4995 [==============================] - 13s 3ms/step - loss: 2018.0323 - accuracy: 0.5667 - val_loss: 1473.0535 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "4995/4995 [==============================] - 12s 2ms/step - loss: 1962.3424 - accuracy: 0.5706 - val_loss: 1520.0557 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "4995/4995 [==============================] - 12s 2ms/step - loss: 1931.2529 - accuracy: 0.5768 - val_loss: 1572.1237 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "4995/4995 [==============================] - 12s 2ms/step - loss: 1914.7915 - accuracy: 0.5692 - val_loss: 1498.5692 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "4995/4995 [==============================] - 12s 2ms/step - loss: 1978.2003 - accuracy: 0.5832 - val_loss: 1543.0012 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "4995/4995 [==============================] - 18s 4ms/step - loss: 1908.6047 - accuracy: 0.5723 - val_loss: 1495.5116 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "4995/4995 [==============================] - 19s 4ms/step - loss: 1962.8383 - accuracy: 0.5906 - val_loss: 1447.4083 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "4995/4995 [==============================] - 18s 4ms/step - loss: 1984.1622 - accuracy: 0.5914 - val_loss: 1487.8463 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "4995/4995 [==============================] - 20s 4ms/step - loss: 1953.3342 - accuracy: 0.5863 - val_loss: 1456.7954 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "4995/4995 [==============================] - 21s 4ms/step - loss: 1965.0099 - accuracy: 0.6063 - val_loss: 1470.8191 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "4995/4995 [==============================] - 18s 4ms/step - loss: 1995.5632 - accuracy: 0.5802 - val_loss: 1529.3853 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "4995/4995 [==============================] - 18s 4ms/step - loss: 1991.9385 - accuracy: 0.6058 - val_loss: 1549.1047 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "4995/4995 [==============================] - 18s 4ms/step - loss: 2002.3098 - accuracy: 0.6200 - val_loss: 1515.8274 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "4995/4995 [==============================] - 18s 4ms/step - loss: 1953.1594 - accuracy: 0.6035 - val_loss: 1542.9946 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "4995/4995 [==============================] - 18s 4ms/step - loss: 1889.2633 - accuracy: 0.6096 - val_loss: 1418.7426 - val_accuracy: 0.0959\n",
      "Epoch 33/100\n",
      "4995/4995 [==============================] - 16s 3ms/step - loss: 1997.6588 - accuracy: 0.6176 - val_loss: 1472.8082 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "4995/4995 [==============================] - 16s 3ms/step - loss: 1990.4247 - accuracy: 0.6122 - val_loss: 1459.4720 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "4995/4995 [==============================] - 23s 5ms/step - loss: 1917.3015 - accuracy: 0.6119 - val_loss: 1546.1177 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "4995/4995 [==============================] - 21s 4ms/step - loss: 1934.3180 - accuracy: 0.5917 - val_loss: 1507.4536 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "4995/4995 [==============================] - 20s 4ms/step - loss: 2029.8838 - accuracy: 0.6066 - val_loss: 1517.2593 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "4995/4995 [==============================] - 20s 4ms/step - loss: 1941.3889 - accuracy: 0.6046 - val_loss: 1473.3129 - val_accuracy: 0.0535\n",
      "Epoch 39/100\n",
      "4995/4995 [==============================] - 19s 4ms/step - loss: 1950.5852 - accuracy: 0.6179 - val_loss: 1576.2297 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "4995/4995 [==============================] - 15s 3ms/step - loss: 1952.4586 - accuracy: 0.6020 - val_loss: 1524.4071 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "4995/4995 [==============================] - 16s 3ms/step - loss: 1983.5245 - accuracy: 0.5982 - val_loss: 1508.9203 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "4995/4995 [==============================] - 17s 3ms/step - loss: 1945.4657 - accuracy: 0.6282 - val_loss: 1451.5266 - val_accuracy: 0.2154\n",
      "Epoch 43/100\n",
      "4995/4995 [==============================] - 13s 3ms/step - loss: 2009.0558 - accuracy: 0.6300 - val_loss: 1574.6259 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "4995/4995 [==============================] - 12s 2ms/step - loss: 1915.5795 - accuracy: 0.5934 - val_loss: 1384.0504 - val_accuracy: 0.7178\n",
      "Epoch 45/100\n",
      "4995/4995 [==============================] - 12s 2ms/step - loss: 1969.0356 - accuracy: 0.6387 - val_loss: 1467.6215 - val_accuracy: 0.1016\n",
      "Epoch 46/100\n",
      "4995/4995 [==============================] - 12s 2ms/step - loss: 2022.8893 - accuracy: 0.6522 - val_loss: 1500.4902 - val_accuracy: 0.0485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100\n",
      "4995/4995 [==============================] - 12s 2ms/step - loss: 1984.7052 - accuracy: 0.5923 - val_loss: 1478.1158 - val_accuracy: 0.1009\n",
      "Epoch 48/100\n",
      "4995/4995 [==============================] - 13s 3ms/step - loss: 1962.3511 - accuracy: 0.6076 - val_loss: 1446.5250 - val_accuracy: 0.1481\n",
      "Epoch 49/100\n",
      "4995/4995 [==============================] - 13s 3ms/step - loss: 2008.5388 - accuracy: 0.6308 - val_loss: 1425.2990 - val_accuracy: 0.1813\n",
      "Epoch 50/100\n",
      "4995/4995 [==============================] - 12s 2ms/step - loss: 1959.2343 - accuracy: 0.6064 - val_loss: 1346.4398 - val_accuracy: 0.7677\n",
      "Epoch 51/100\n",
      "4995/4995 [==============================] - 12s 2ms/step - loss: 1965.0155 - accuracy: 0.6230 - val_loss: 1464.7053 - val_accuracy: 0.0667\n",
      "Epoch 52/100\n",
      "4995/4995 [==============================] - 12s 2ms/step - loss: 1977.0648 - accuracy: 0.6189 - val_loss: 1478.6978 - val_accuracy: 0.0578\n",
      "Epoch 53/100\n",
      "4995/4995 [==============================] - 12s 2ms/step - loss: 1977.0292 - accuracy: 0.6271 - val_loss: 1528.9781 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "4995/4995 [==============================] - 12s 2ms/step - loss: 1944.4064 - accuracy: 0.6270 - val_loss: 1414.6044 - val_accuracy: 0.2465\n",
      "Epoch 55/100\n",
      "4995/4995 [==============================] - 12s 2ms/step - loss: 1997.5527 - accuracy: 0.6092 - val_loss: 1524.9675 - val_accuracy: 0.0016\n",
      "Epoch 56/100\n",
      "4995/4995 [==============================] - 12s 2ms/step - loss: 1953.3116 - accuracy: 0.6208 - val_loss: 1505.3184 - val_accuracy: 0.0566\n",
      "Epoch 57/100\n",
      "4995/4995 [==============================] - 12s 2ms/step - loss: 1950.6385 - accuracy: 0.6222 - val_loss: 1448.5963 - val_accuracy: 0.1193\n",
      "Epoch 58/100\n",
      "4995/4995 [==============================] - 12s 2ms/step - loss: 2019.6528 - accuracy: 0.6091 - val_loss: 1431.0098 - val_accuracy: 0.1501\n",
      "Epoch 59/100\n",
      "4995/4995 [==============================] - 12s 2ms/step - loss: 1949.2175 - accuracy: 0.6347 - val_loss: 1469.4316 - val_accuracy: 0.1184\n",
      "Epoch 60/100\n",
      "4995/4995 [==============================] - 12s 2ms/step - loss: 1933.7120 - accuracy: 0.6466 - val_loss: 1513.8484 - val_accuracy: 0.0510\n",
      "Epoch 61/100\n",
      "4995/4995 [==============================] - 12s 2ms/step - loss: 1916.6384 - accuracy: 0.6286 - val_loss: 1534.0243 - val_accuracy: 0.0319\n",
      "Epoch 62/100\n",
      "4995/4995 [==============================] - 12s 2ms/step - loss: 1939.9849 - accuracy: 0.6136 - val_loss: 1556.2615 - val_accuracy: 0.0305\n",
      "Epoch 63/100\n",
      "4995/4995 [==============================] - 13s 3ms/step - loss: 2003.2552 - accuracy: 0.6013 - val_loss: 1399.2366 - val_accuracy: 0.6774\n",
      "Epoch 64/100\n",
      "4995/4995 [==============================] - 13s 3ms/step - loss: 1993.4928 - accuracy: 0.6314 - val_loss: 1465.4178 - val_accuracy: 0.1193\n",
      "Epoch 65/100\n",
      "4995/4995 [==============================] - 12s 2ms/step - loss: 1996.7662 - accuracy: 0.6173 - val_loss: 1441.5996 - val_accuracy: 0.1593\n",
      "Epoch 66/100\n",
      "4995/4995 [==============================] - 13s 3ms/step - loss: 1984.2700 - accuracy: 0.6269 - val_loss: 1527.4210 - val_accuracy: 0.0067\n",
      "Epoch 67/100\n",
      "4995/4995 [==============================] - 12s 2ms/step - loss: 1884.3961 - accuracy: 0.6154 - val_loss: 1516.1530 - val_accuracy: 0.0943\n",
      "Epoch 68/100\n",
      "4995/4995 [==============================] - 12s 2ms/step - loss: 1998.7654 - accuracy: 0.6162 - val_loss: 1488.2944 - val_accuracy: 0.1564\n",
      "Epoch 69/100\n",
      "4995/4995 [==============================] - 13s 3ms/step - loss: 1996.2076 - accuracy: 0.6287 - val_loss: 1460.6722 - val_accuracy: 0.2691\n",
      "Epoch 70/100\n",
      "4995/4995 [==============================] - 12s 2ms/step - loss: 1977.2980 - accuracy: 0.6387 - val_loss: 1493.8601 - val_accuracy: 0.1307\n",
      "Epoch 71/100\n",
      "4995/4995 [==============================] - 12s 2ms/step - loss: 1956.0131 - accuracy: 0.6273 - val_loss: 1462.0156 - val_accuracy: 0.2764\n",
      "Epoch 72/100\n",
      "4995/4995 [==============================] - 13s 3ms/step - loss: 2028.2323 - accuracy: 0.6127 - val_loss: 1566.0856 - val_accuracy: 0.0943\n",
      "Epoch 73/100\n",
      "4995/4995 [==============================] - 14s 3ms/step - loss: 1965.9266 - accuracy: 0.6236 - val_loss: 1516.3866 - val_accuracy: 0.2712\n",
      "Epoch 74/100\n",
      "4995/4995 [==============================] - 12s 2ms/step - loss: 1973.3655 - accuracy: 0.6415 - val_loss: 1467.0552 - val_accuracy: 0.6774\n",
      "Epoch 75/100\n",
      "4995/4995 [==============================] - 14s 3ms/step - loss: 1963.4274 - accuracy: 0.6283 - val_loss: 1506.8533 - val_accuracy: 0.3716\n",
      "Epoch 76/100\n",
      "4995/4995 [==============================] - 19s 4ms/step - loss: 1945.6276 - accuracy: 0.6291 - val_loss: 1532.9681 - val_accuracy: 0.3469\n",
      "Epoch 77/100\n",
      "4995/4995 [==============================] - 19s 4ms/step - loss: 1965.1805 - accuracy: 0.6285 - val_loss: 1447.4508 - val_accuracy: 0.9054\n",
      "Epoch 78/100\n",
      "4739/4995 [===========================>..] - ETA: 0s - loss: 1740.5426 - accuracy: 0.6676"
     ]
    }
   ],
   "source": [
    "print('Init Train')\n",
    "start = timer()\n",
    "history = model.fit(\n",
    "    X_train, Y_train, \n",
    "    epochs=100, \n",
    "    batch_size= 10,\n",
    "    validation_split=0.1,\n",
    "    shuffle=False,\n",
    "#     callbacks=[tensorboard_callback]\n",
    ")\n",
    "print('trraining duration: ',round(timer() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Saving Model')\n",
    "model.save('models/mlp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "\n",
    "\n",
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(1,1,1)\n",
    "ax1.plot(history.history['loss'], label='train')\n",
    "ax1.plot(history.history['val_loss'], label='validation')\n",
    "ax1.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(1,1,1)\n",
    "ax1.plot(history.history['accuracy'], label='train')\n",
    "ax1.plot(history.history['val_accuracy'], label='validation')\n",
    "ax1.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unormalizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_columns = ['temperature','label']\n",
    "scaler1 = StandardScaler().fit(train[f_columns])\n",
    "scaler2 = StandardScaler().fit(train[f_columns])\n",
    "\n",
    "scaler1= scaler1.fit(train[f_columns].to_numpy())\n",
    "scaler2 = scaler2.fit(train[['delay']])\n",
    "\n",
    "\n",
    "#normalizando test\n",
    "scaler3 = StandardScaler().fit(test[f_columns])\n",
    "scaler4 = StandardScaler().fit(test[f_columns])\n",
    "\n",
    "scaler3 = scaler3.fit(test[f_columns].to_numpy())\n",
    "scaler4 = scaler4.fit(test[['delay']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_inv = scaler4.inverse_transform(Y_test.reshape(1,-1))\n",
    "y_pred_inv = scaler4.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plt.figure()\n",
    "a2 = fig2.add_subplot(1,1,1)\n",
    "a2.plot(y_test_inv.flatten(), marker='.', label='true')\n",
    "a2.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig3 = plt.figure()\n",
    "a3 = fig3.add_subplot(1,1,1)\n",
    "a3.plot(y_pred_inv.flatten(),'r',marker='.', label='predicted')\n",
    "a3.legend();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(y_test_inv.flatten(), marker='.', label='true')\n",
    "\n",
    "plt.plot(y_pred_inv.flatten(),'r',marker='.', label='predicted')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = []\n",
    "l2 = []\n",
    "for i in np.arange(y_pred_inv.shape[0]):\n",
    "    clear_output(wait=True)\n",
    "    print('progress ',round((i/y_pred_inv.shape[0])*100,2), ('%'))\n",
    "    if(y_pred_inv[i,0,0]<=350000):\n",
    "        l1.append(y_pred_inv[i])\n",
    "    if(y_test_inv[0,i]<=350000):\n",
    "        l2.append(y_test_inv[0,i])\n",
    "\n",
    "y_pred_inv2 = np.array(l1)\n",
    "y_test_inv2 = np.array(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(y_test_inv2.flatten(), marker='.', label='true')\n",
    "\n",
    "plt.plot(y_pred_inv2.flatten(),'r',marker='.', label='predicted')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(y_test_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(y_pred_inv[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test_inv[0], y_pred_inv[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse =  mean_squared_error(y_test_inv[0], y_pred_inv[:,0])\n",
    "mae =  mean_absolute_error(y_test_inv[0], y_pred_inv[:,0])\n",
    "median_mae = median_absolute_error(y_test_inv[0], y_pred_inv[:,0])\n",
    "msle = mean_squared_log_error(y_test_inv[0], y_pred_inv[:,0])\n",
    "r2_score = r2_score(y_test_inv[0], y_pred_inv[:,0])\n",
    "\n",
    "print(mse)\n",
    "print(mae)\n",
    "print(median_mae)\n",
    "print(msle)\n",
    "print(r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
