{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skmultiflow.drift_detection import PageHinkley\n",
    "from IPython.display import clear_output\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveFile(dataset, name='dataset'):\n",
    "    print('saving: ',name, '......')\n",
    "    f = open(name,'w')\n",
    "    try:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(dataset.columns)\n",
    "        for i in np.arange(int(dataset.shape[0])):\n",
    "            writer.writerow(dataset.iloc[i,])\n",
    "    finally:\n",
    "        f.close()\n",
    " \n",
    "def create_window(X, time_steps=5):\n",
    "    Xs = []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        clear_output(wait=True)\n",
    "        print('creating concept window ',round((i/(len(X) - time_steps))*100,2), ('%'))\n",
    "        v = X.iloc[i: (i+time_steps), 2].to_numpy()\n",
    "        Xs.append(v)                     \n",
    "    return np.array(Xs)\n",
    "\n",
    "def getConceptDrifft(data_stream, dataset):\n",
    "    ph = PageHinkley(1)\n",
    "\n",
    "    # Adding stream elements to the PageHinkley drift detector and verifying if drift occurred\n",
    "    CHANGE = 0\n",
    "    lastconcept=0\n",
    "    for i in range(1,data_stream.shape[0]):          \n",
    "        clear_output(wait=True)\n",
    "        print('checking concept drift ',round((i/(data_stream.shape[0]))*100,2), ('%'))\n",
    "        for j in np.arange(data_stream[i].shape[0]):  \n",
    "            ph.add_element(data_stream[i][j])\n",
    "            if ph.detected_change():\n",
    "                CHANGE = 1\n",
    "                break\n",
    "\n",
    "        init = (i-1)*WINDOW  \n",
    "\n",
    "        if(CHANGE):   \n",
    "            DELAY= (dataset.iloc[i, 1] - dataset.iloc[lastconcept, 1])\n",
    "            dataset.iloc[init: (init+WINDOW), 4] =  DELAY\n",
    "            dataset.iloc[init: (init+WINDOW),3] =  CHANGE\n",
    "            CHANGE = 0\n",
    "            lastconcept = i\n",
    "            \n",
    "        else:\n",
    "            DELAY= (dataset.iloc[i, 1] - dataset.iloc[(i-1), 1])\n",
    "            dataset.iloc[init: (init+WINDOW), 4] =  DELAY\n",
    "            dataset.iloc[init: (init+WINDOW),3] =  CHANGE\n",
    "        print('concept: '+str(CHANGE)+' - delay: '+str(DELAY))\n",
    "    return dataset\n",
    "    \n",
    "def normalizing(dataset):\n",
    "    print('loading Normalizing')\n",
    "    #colunas que serão normalizadas\n",
    "    f_columns = ['temperature','label']\n",
    "    \n",
    "    #normalizando train\n",
    "    scaler1 = StandardScaler().fit(dataset[f_columns])\n",
    "    scaler2 = StandardScaler().fit(dataset[f_columns])\n",
    "    \n",
    "    scaler1= scaler1.fit(dataset[f_columns].to_numpy())\n",
    "    scaler2 = scaler2.fit(dataset[['delay']])\n",
    "    \n",
    "    dataset.loc[:,f_columns] = scaler1.transform(dataset[f_columns].to_numpy())\n",
    "    dataset['delay'] = scaler2.transform(dataset[['delay']])\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "    \n",
    "#carregando datasets\n",
    "print('loading dataset')\n",
    "\n",
    "train1  = pd.read_csv('../datasets/sem_concept_drift/sdn_train1.csv', delimiter=\",\")\n",
    "train2  = pd.read_csv('../datasets/sem_concept_drift/sdn_train2.csv', delimiter=\",\")\n",
    "train3  = pd.read_csv('../datasets/sem_concept_drift/sdn_train3.csv', delimiter=\",\")\n",
    "WINDOW = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test  = pd.read_csv('../datasets/sem_concept_drift/sdn_test.csv', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking concept drift  100.0 %\n",
      "concept: 0 - delay: 56.0\n"
     ]
    }
   ],
   "source": [
    "#gerando concept drift train\n",
    "print('loading train concept drift')\n",
    "data_stream_train1 = create_window(train1, time_steps=WINDOW)\n",
    "train1 = getConceptDrifft(data_stream_train1, train1)\n",
    "\n",
    "data_stream_train2 = create_window(train2, time_steps=WINDOW)\n",
    "train2 = getConceptDrifft(data_stream_train2, train2)\n",
    "\n",
    "data_stream_train3 = create_window(train3, time_steps=WINDOW)\n",
    "train3 = getConceptDrifft(data_stream_train3, train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking concept drift  100.0 %\n",
      "concept: 0 - delay: 1995.0\n"
     ]
    }
   ],
   "source": [
    "#gerando concept drift test\n",
    "print('loading test concept drift')\n",
    "data_stream_test = create_window(test, time_steps=WINDOW)\n",
    "test= getConceptDrifft(data_stream_test, test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving:  ../datasets/com_concept_drift/sdn_train_unormalized1.csv ......\n",
      "saving:  ../datasets/com_concept_drift/sdn_train_unormalized2.csv ......\n",
      "saving:  ../datasets/com_concept_drift/sdn_train_unormalized3.csv ......\n"
     ]
    }
   ],
   "source": [
    "#salvando datasets normalizados\n",
    "saveFile(train1, name='../datasets/com_concept_drift/sdn_train_unormalized1.csv')\n",
    "saveFile(train2, name='../datasets/com_concept_drift/sdn_train_unormalized2.csv')\n",
    "saveFile(train3, name='../datasets/com_concept_drift/sdn_train_unormalized3.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving:  ../datasets/com_concept_drift/sdn_test_unormalized.csv ......\n"
     ]
    }
   ],
   "source": [
    "saveFile(test, name='../datasets/com_concept_drift/sdn_test_unormalized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Normalizing\n",
      "loading Normalizing\n",
      "loading Normalizing\n"
     ]
    }
   ],
   "source": [
    "#normalizando datasets\n",
    "train1 = normalizing(train1)\n",
    "train2 = normalizing(train2)\n",
    "train3 = normalizing(train3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Normalizing\n"
     ]
    }
   ],
   "source": [
    "test = normalizing(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving:  ../datasets/com_concept_drift/sdn_train_normalized1.csv ......\n",
      "saving:  ../datasets/com_concept_drift/sdn_train_normalized2.csv ......\n",
      "saving:  ../datasets/com_concept_drift/sdn_train_normalized3.csv ......\n"
     ]
    }
   ],
   "source": [
    "#salvando datasets normalizados\n",
    "saveFile(train1, name='../datasets/com_concept_drift/sdn_train_normalized1.csv')\n",
    "saveFile(train2, name='../datasets/com_concept_drift/sdn_train_normalized2.csv')\n",
    "saveFile(train3, name='../datasets/com_concept_drift/sdn_train_normalized3.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving:  ../datasets/com_concept_drift/sdn_test_normalized.csv ......\n",
      "duração:  717.0795847\n"
     ]
    }
   ],
   "source": [
    "saveFile(test, name='../datasets/com_concept_drift/sdn_test_normalized.csv')\n",
    "print('duração: ', timer() - start) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
